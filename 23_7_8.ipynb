{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 2-1 Phoneme Classification**"
      ],
      "metadata": {
        "id": "uNtpcyvAQiib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result\n",
        "\n",
        "scores:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "strong baseline:\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ZpoD-A07RR2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "Wwj8uzoSQtNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXkyoCyMb0_0",
        "outputId": "d37a41a8-1d79-4b9e-a25c-5cf780931592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR\n",
            "To: /content/data.zip\n",
            "100% 372M/372M [00:01<00:00, 198MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: timit_11/\n",
            "  inflating: timit_11/train_11.npy   \n",
            "  inflating: timit_11/test_11.npy    \n",
            "  inflating: timit_11/train_label_11.npy  \n",
            "data.zip  sample_data  timit_11\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
        "!unzip data.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "Ix7ILFscQx_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ilJ01krSb5W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab818be7-b29e-4b2f-9254-bf57ee060bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Loading data ...')\n",
        "\n",
        "data_root='./timit_11/'\n",
        "train = np.load(data_root + 'train_11.npy')\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "\n",
        "print('Size of training data: {}'.format(train.shape))\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "ALjm4siwQ2BY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2q7PmAgpiJU3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "  def __init__(self, X, y=None):\n",
        "    self.data = torch.from_numpy(X).float()\n",
        "\n",
        "    if y is not None:\n",
        "      y = y.astype(float)\n",
        "      self.label = torch.LongTensor(y)\n",
        "\n",
        "    else:\n",
        "      self.label = None\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.label is not None:\n",
        "      return self.data[idx], self.label[idx]\n",
        "\n",
        "    else:\n",
        "      return self.data[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "upBWdusqxaaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afab2a1-82e4-4b35-eaea-5c2266f95fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: (983945, 429)\n",
            "Size of validation set: (245987, 429)\n"
          ]
        }
      ],
      "source": [
        "VAL_RATIO = 0.2\n",
        "\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
        "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RtudKuiZxcvs"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "val_set = TIMITDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WxHK9yCwxjct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247fea96-05d1-41eb-ea32-d8e4559b4263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "del train, train_label, train_x, train_y, val_x, val_y\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "FoFThi9DQ7Pl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZzIbjUoNjXY1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(429, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(512, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(1024, 2048),\n",
        "      nn.BatchNorm1d(2048),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.Linear(2048, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(512, 256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(256, 128),\n",
        "      nn.BatchNorm1d(128),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.Linear(128, 39),\n",
        "    )\n",
        "\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.net(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def cal_loss(self, pred, target):\n",
        "\n",
        "    l2 = 0\n",
        "    for i in self.parameters():\n",
        "      l2 += torch.sum(torch.pow(i, 2))\n",
        "\n",
        "    loss = self.criterion(pred, target)\n",
        "\n",
        "    return loss + 0.01 * l2, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "bZJM1BLXQ--o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oIxje0WYsimB"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "  return \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nVC9nAsHvSRq"
      },
      "outputs": [],
      "source": [
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5gF3hhTcvWKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a646684e-ae51-4b81-edb6-1c1ea94d03dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "same_seeds(0)\n",
        "\n",
        "device = get_device()\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "num_epoch = 100\n",
        "learning_rate = 1e-3\n",
        "\n",
        "model_path = './model.ckpt'\n",
        "\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kAjavMwFqpaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a66f7b-d581-4ef0-f678-42b425ac8e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/100] Train Acc: 0.668715 Loss: 1.243308 | Val Acc: 0.698708 loss: 1.125849\n",
            "saving model with acc 0.699\n",
            "[002/100] Train Acc: 0.679065 Loss: 1.211470 | Val Acc: 0.704224 loss: 1.110216\n",
            "saving model with acc 0.704\n",
            "[003/100] Train Acc: 0.683408 Loss: 1.196558 | Val Acc: 0.706732 loss: 1.093267\n",
            "saving model with acc 0.707\n",
            "[004/100] Train Acc: 0.685265 Loss: 1.185725 | Val Acc: 0.711119 loss: 1.072653\n",
            "saving model with acc 0.711\n",
            "[005/100] Train Acc: 0.686973 Loss: 1.177433 | Val Acc: 0.711464 loss: 1.077814\n",
            "saving model with acc 0.711\n",
            "[006/100] Train Acc: 0.688686 Loss: 1.171454 | Val Acc: 0.713444 loss: 1.068292\n",
            "saving model with acc 0.713\n",
            "[007/100] Train Acc: 0.689848 Loss: 1.166724 | Val Acc: 0.710660 loss: 1.072013\n",
            "[008/100] Train Acc: 0.691208 Loss: 1.161984 | Val Acc: 0.712790 loss: 1.063485\n",
            "[009/100] Train Acc: 0.692147 Loss: 1.158303 | Val Acc: 0.712282 loss: 1.067403\n",
            "[010/100] Train Acc: 0.693951 Loss: 1.155002 | Val Acc: 0.715497 loss: 1.064845\n",
            "saving model with acc 0.715\n",
            "[011/100] Train Acc: 0.694279 Loss: 1.153067 | Val Acc: 0.715493 loss: 1.056535\n",
            "[012/100] Train Acc: 0.694760 Loss: 1.150761 | Val Acc: 0.717644 loss: 1.054698\n",
            "saving model with acc 0.718\n",
            "[013/100] Train Acc: 0.695963 Loss: 1.148888 | Val Acc: 0.718510 loss: 1.049219\n",
            "saving model with acc 0.719\n",
            "[014/100] Train Acc: 0.696003 Loss: 1.148089 | Val Acc: 0.717534 loss: 1.052256\n",
            "[015/100] Train Acc: 0.696514 Loss: 1.145675 | Val Acc: 0.714806 loss: 1.062187\n",
            "[016/100] Train Acc: 0.696859 Loss: 1.145978 | Val Acc: 0.719664 loss: 1.046396\n",
            "saving model with acc 0.720\n",
            "[017/100] Train Acc: 0.697195 Loss: 1.144596 | Val Acc: 0.717087 loss: 1.053259\n",
            "[018/100] Train Acc: 0.696989 Loss: 1.142874 | Val Acc: 0.719481 loss: 1.044389\n",
            "[019/100] Train Acc: 0.697512 Loss: 1.142341 | Val Acc: 0.716981 loss: 1.048176\n",
            "[020/100] Train Acc: 0.697707 Loss: 1.142121 | Val Acc: 0.720664 loss: 1.039796\n",
            "saving model with acc 0.721\n",
            "[021/100] Train Acc: 0.698583 Loss: 1.141470 | Val Acc: 0.718579 loss: 1.048515\n",
            "[022/100] Train Acc: 0.697984 Loss: 1.141547 | Val Acc: 0.719904 loss: 1.043003\n",
            "[023/100] Train Acc: 0.698070 Loss: 1.139873 | Val Acc: 0.717579 loss: 1.050415\n",
            "[024/100] Train Acc: 0.698541 Loss: 1.139254 | Val Acc: 0.721237 loss: 1.040128\n",
            "saving model with acc 0.721\n",
            "[025/100] Train Acc: 0.697777 Loss: 1.138737 | Val Acc: 0.719623 loss: 1.044508\n",
            "[026/100] Train Acc: 0.698819 Loss: 1.138531 | Val Acc: 0.719058 loss: 1.041008\n",
            "[027/100] Train Acc: 0.698943 Loss: 1.137330 | Val Acc: 0.719050 loss: 1.046507\n",
            "[028/100] Train Acc: 0.699697 Loss: 1.135473 | Val Acc: 0.720034 loss: 1.039034\n",
            "[029/100] Train Acc: 0.698997 Loss: 1.136055 | Val Acc: 0.720798 loss: 1.037208\n",
            "[030/100] Train Acc: 0.699244 Loss: 1.135450 | Val Acc: 0.719587 loss: 1.040971\n",
            "[031/100] Train Acc: 0.699835 Loss: 1.134418 | Val Acc: 0.720725 loss: 1.043664\n",
            "[032/100] Train Acc: 0.699876 Loss: 1.134451 | Val Acc: 0.720628 loss: 1.038919\n",
            "[033/100] Train Acc: 0.699764 Loss: 1.134799 | Val Acc: 0.720949 loss: 1.036548\n",
            "[034/100] Train Acc: 0.699558 Loss: 1.134470 | Val Acc: 0.718969 loss: 1.043812\n",
            "[035/100] Train Acc: 0.699542 Loss: 1.134261 | Val Acc: 0.721884 loss: 1.032876\n",
            "saving model with acc 0.722\n",
            "[036/100] Train Acc: 0.728792 Loss: 1.046140 | Val Acc: 0.743186 loss: 0.967601\n",
            "saving model with acc 0.743\n",
            "[037/100] Train Acc: 0.740013 Loss: 1.008659 | Val Acc: 0.743942 loss: 0.959416\n",
            "saving model with acc 0.744\n",
            "[038/100] Train Acc: 0.745270 Loss: 0.989933 | Val Acc: 0.745702 loss: 0.952778\n",
            "saving model with acc 0.746\n",
            "[039/100] Train Acc: 0.748863 Loss: 0.976693 | Val Acc: 0.745682 loss: 0.948729\n",
            "[040/100] Train Acc: 0.751886 Loss: 0.965097 | Val Acc: 0.746060 loss: 0.945459\n",
            "saving model with acc 0.746\n",
            "[041/100] Train Acc: 0.753931 Loss: 0.956839 | Val Acc: 0.746584 loss: 0.943678\n",
            "saving model with acc 0.747\n",
            "[042/100] Train Acc: 0.755522 Loss: 0.950400 | Val Acc: 0.746019 loss: 0.942533\n",
            "[043/100] Train Acc: 0.757293 Loss: 0.944737 | Val Acc: 0.745527 loss: 0.943327\n",
            "[044/100] Train Acc: 0.759246 Loss: 0.938058 | Val Acc: 0.747044 loss: 0.939559\n",
            "saving model with acc 0.747\n",
            "[045/100] Train Acc: 0.759741 Loss: 0.935068 | Val Acc: 0.746165 loss: 0.940300\n",
            "[046/100] Train Acc: 0.760572 Loss: 0.930942 | Val Acc: 0.746576 loss: 0.940283\n",
            "[047/100] Train Acc: 0.761531 Loss: 0.928159 | Val Acc: 0.746226 loss: 0.941386\n",
            "[048/100] Train Acc: 0.762603 Loss: 0.924050 | Val Acc: 0.745011 loss: 0.942660\n",
            "[049/100] Train Acc: 0.763222 Loss: 0.921571 | Val Acc: 0.746308 loss: 0.940687\n",
            "[050/100] Train Acc: 0.763686 Loss: 0.918847 | Val Acc: 0.745820 loss: 0.940774\n",
            "[051/100] Train Acc: 0.764815 Loss: 0.916726 | Val Acc: 0.745369 loss: 0.940465\n",
            "[052/100] Train Acc: 0.764541 Loss: 0.916003 | Val Acc: 0.744808 loss: 0.941396\n",
            "[053/100] Train Acc: 0.764923 Loss: 0.915253 | Val Acc: 0.745901 loss: 0.939545\n",
            "[054/100] Train Acc: 0.765592 Loss: 0.913285 | Val Acc: 0.745182 loss: 0.940604\n",
            "[055/100] Train Acc: 0.765865 Loss: 0.911683 | Val Acc: 0.745523 loss: 0.943725\n",
            "[056/100] Train Acc: 0.765348 Loss: 0.911704 | Val Acc: 0.746759 loss: 0.936433\n",
            "[057/100] Train Acc: 0.766188 Loss: 0.908920 | Val Acc: 0.745828 loss: 0.942434\n",
            "[058/100] Train Acc: 0.766962 Loss: 0.907764 | Val Acc: 0.745690 loss: 0.937279\n",
            "[059/100] Train Acc: 0.767512 Loss: 0.905279 | Val Acc: 0.745007 loss: 0.940300\n",
            "[060/100] Train Acc: 0.767654 Loss: 0.904783 | Val Acc: 0.746060 loss: 0.939682\n",
            "[061/100] Train Acc: 0.767696 Loss: 0.904538 | Val Acc: 0.745251 loss: 0.940066\n",
            "[062/100] Train Acc: 0.767925 Loss: 0.903275 | Val Acc: 0.744499 loss: 0.941742\n",
            "[063/100] Train Acc: 0.768762 Loss: 0.901546 | Val Acc: 0.745312 loss: 0.940251\n",
            "[064/100] Train Acc: 0.768771 Loss: 0.901239 | Val Acc: 0.745596 loss: 0.938039\n",
            "[065/100] Train Acc: 0.768801 Loss: 0.900109 | Val Acc: 0.745287 loss: 0.944460\n",
            "[066/100] Train Acc: 0.769455 Loss: 0.898480 | Val Acc: 0.745861 loss: 0.941579\n",
            "[067/100] Train Acc: 0.770078 Loss: 0.897045 | Val Acc: 0.744726 loss: 0.944020\n",
            "[068/100] Train Acc: 0.770413 Loss: 0.896145 | Val Acc: 0.745722 loss: 0.941940\n",
            "[069/100] Train Acc: 0.770475 Loss: 0.895605 | Val Acc: 0.745157 loss: 0.939427\n",
            "[070/100] Train Acc: 0.770717 Loss: 0.894757 | Val Acc: 0.744982 loss: 0.940981\n",
            "[071/100] Train Acc: 0.770542 Loss: 0.894490 | Val Acc: 0.745035 loss: 0.941513\n",
            "[072/100] Train Acc: 0.771543 Loss: 0.891845 | Val Acc: 0.745535 loss: 0.943055\n",
            "[073/100] Train Acc: 0.770858 Loss: 0.893745 | Val Acc: 0.746531 loss: 0.938895\n",
            "[074/100] Train Acc: 0.771290 Loss: 0.891285 | Val Acc: 0.743612 loss: 0.944992\n",
            "[075/100] Train Acc: 0.771730 Loss: 0.891322 | Val Acc: 0.743584 loss: 0.944360\n",
            "[076/100] Train Acc: 0.772037 Loss: 0.890187 | Val Acc: 0.744352 loss: 0.946721\n",
            "[077/100] Train Acc: 0.772668 Loss: 0.888727 | Val Acc: 0.743438 loss: 0.946058\n",
            "[078/100] Train Acc: 0.772192 Loss: 0.889107 | Val Acc: 0.744243 loss: 0.945641\n",
            "[079/100] Train Acc: 0.773039 Loss: 0.887958 | Val Acc: 0.744072 loss: 0.945622\n",
            "[080/100] Train Acc: 0.773094 Loss: 0.886315 | Val Acc: 0.744832 loss: 0.943067\n",
            "[081/100] Train Acc: 0.773075 Loss: 0.886779 | Val Acc: 0.744430 loss: 0.942643\n",
            "[082/100] Train Acc: 0.773381 Loss: 0.885153 | Val Acc: 0.743751 loss: 0.945713\n",
            "[083/100] Train Acc: 0.773169 Loss: 0.885369 | Val Acc: 0.745222 loss: 0.943257\n",
            "[084/100] Train Acc: 0.773969 Loss: 0.884817 | Val Acc: 0.743596 loss: 0.947535\n",
            "[085/100] Train Acc: 0.773920 Loss: 0.884317 | Val Acc: 0.744365 loss: 0.946409\n",
            "[086/100] Train Acc: 0.774054 Loss: 0.883256 | Val Acc: 0.745482 loss: 0.940835\n",
            "[087/100] Train Acc: 0.774699 Loss: 0.881790 | Val Acc: 0.745917 loss: 0.944154\n",
            "[088/100] Train Acc: 0.775030 Loss: 0.880736 | Val Acc: 0.744966 loss: 0.944277\n",
            "[089/100] Train Acc: 0.774730 Loss: 0.881740 | Val Acc: 0.743206 loss: 0.945251\n",
            "[090/100] Train Acc: 0.774688 Loss: 0.881323 | Val Acc: 0.744962 loss: 0.944985\n",
            "[091/100] Train Acc: 0.774408 Loss: 0.881271 | Val Acc: 0.744499 loss: 0.942958\n",
            "[092/100] Train Acc: 0.775246 Loss: 0.880195 | Val Acc: 0.744921 loss: 0.943865\n",
            "[093/100] Train Acc: 0.775550 Loss: 0.879250 | Val Acc: 0.745214 loss: 0.943035\n",
            "[094/100] Train Acc: 0.775375 Loss: 0.879564 | Val Acc: 0.744596 loss: 0.944814\n",
            "[095/100] Train Acc: 0.775607 Loss: 0.878649 | Val Acc: 0.743556 loss: 0.946925\n",
            "[096/100] Train Acc: 0.775940 Loss: 0.877357 | Val Acc: 0.745470 loss: 0.944610\n",
            "[097/100] Train Acc: 0.775149 Loss: 0.878704 | Val Acc: 0.743182 loss: 0.946575\n",
            "[098/100] Train Acc: 0.775540 Loss: 0.877635 | Val Acc: 0.745194 loss: 0.943795\n",
            "[099/100] Train Acc: 0.776194 Loss: 0.876341 | Val Acc: 0.746409 loss: 0.941551\n",
            "[100/100] Train Acc: 0.775834 Loss: 0.876859 | Val Acc: 0.745324 loss: 0.943642\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        l2_loss, batch_loss = model.cal_loss(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1)\n",
        "        l2_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    if len(val_set) > 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, batch_loss = model.cal_loss(outputs, labels)\n",
        "                _, val_pred = torch.max(outputs, 1)\n",
        "\n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "\n",
        "\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "euEW1A3RREYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XZnNWoLvvYH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd01565-deb2-4788-f418-362213591137"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RIH9U_ZKvZpi"
      },
      "outputs": [],
      "source": [
        "predict = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1)\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Bw2mFVH0vbFt"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}